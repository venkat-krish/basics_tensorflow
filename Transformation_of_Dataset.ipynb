{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformation of Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPT0pV8jEXCR0LlLbDNWgk4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkat-krish/basics_tensorflow/blob/master/Transformation_of_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3LqiNjtLOJD",
        "colab_type": "text"
      },
      "source": [
        "# Creating input data pipeline in Tensorflow\n",
        "\n",
        "Data pipeline can be created using tf.data API in tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YI-oFNxLXly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6mkHK-WLMry",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "f72a213c-fb9c-4f91-a2a3-649916719291"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  !pip install tf-nightly-2.0-preview\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly-2.0-preview\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/be/e4e2cc0b4896648fe6d5e45dda6d8c3b784823301708cfe4ff96de9e01cf/tf_nightly_2.0_preview-2.0.0.dev20191002-cp36-cp36m-manylinux2010_x86_64.whl (95.2MB)\n",
            "\u001b[K     |████████████████████████████████| 95.2MB 93kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.0.8)\n",
            "Collecting tb-nightly<2.2.0a0,>=2.1.0a0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/6b/b9e735120c77721570aed36cec55390827db0d580b14a5ffd93a4cce5997/tb_nightly-2.1.0a20191206-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 35.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.34.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.11.2)\n",
            "Collecting tensorflow-estimator-2.0-preview\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/f5/790508e193121ab301cb40cada7f451c531404051ac9249f21b1f5484450/tensorflow_estimator_2.0_preview-2.0.0-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 50.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.1.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (3.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.27.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.17.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tf-nightly-2.0-preview) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-2.0-preview) (1.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-2.0-preview) (2.21.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-2.0-preview) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-2.0-preview) (1.7.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-2.0-preview) (45.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-2.0-preview) (3.2.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-2.0-preview) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-2.0-preview) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-2.0-preview) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-2.0-preview) (2019.11.28)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-2.0-preview) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-2.0-preview) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-2.0-preview) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-2.0-preview) (4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-2.0-preview) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-2.0-preview) (0.4.8)\n",
            "Installing collected packages: tb-nightly, tensorflow-estimator-2.0-preview, tf-nightly-2.0-preview\n",
            "Successfully installed tb-nightly-2.1.0a20191206 tensorflow-estimator-2.0-preview-2.0.0 tf-nightly-2.0-preview-2.0.0.dev20191002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgDThOevLil0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(precision=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ArnJW_CL5K8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42bb0893-519b-43f7-d4d4-879367c7d864"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([8,3,0,8,2,1])\n",
        "dataset # Resulting dataset is a scalar which does not have any size"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e68BmwdxMKny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "3c165ec0-40b5-487d-d865-16d4ed548bf3"
      },
      "source": [
        "for elem in dataset:\n",
        "  print(elem.numpy())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "3\n",
            "0\n",
            "8\n",
            "2\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlvtaOP_MQTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49aad4a7-5a59-4e70-d7c3-9203a0a071a0"
      },
      "source": [
        "# we can use python iterator to iterate over the dataset\n",
        "it = iter(dataset)\n",
        "print(next(it).numpy())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K24j4U6uM4tI",
        "colab_type": "text"
      },
      "source": [
        "Transformation of the dataset can be performed by transform functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkLBu2NiMoLo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "146a4502-f3fd-4333-d2b6-3dd594a053f6"
      },
      "source": [
        "# here the transform function is reduce function which does the sum of given dataset values\n",
        "print(dataset.reduce(0, lambda state, value: state + value).numpy())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLXGkaRENbwM",
        "colab_type": "text"
      },
      "source": [
        "### Dataset structure\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bz4A56ANNc7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cbee78a2-cee1-4978-89c2-df86299a2e60"
      },
      "source": [
        "dataset1 = tf.data.Dataset.from_tensor_slices(tf.random.uniform([4,10]))\n",
        "dataset1.element_spec"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorSpec(shape=(10,), dtype=tf.float32, name=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE0b1aJPNeSX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "818fb6a0-9317-4a38-acd1-713f9911d959"
      },
      "source": [
        "dataset2 = tf.data.Dataset.from_tensor_slices(\n",
        "    (tf.random.uniform([4]),\n",
        "    tf.random.uniform([4,100], maxval=100, dtype=tf.int32)))\n",
        "dataset2.element_spec"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(100,), dtype=tf.int32, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-OXd9aVOfNY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "ee0a3fd9-1d85-46a0-e2bf-1e99ae62b83b"
      },
      "source": [
        "dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
        "dataset3.element_spec"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(10,), dtype=tf.float32, name=None),\n",
              " (TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
              "  TensorSpec(shape=(100,), dtype=tf.int32, name=None)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2ahjqswOw-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1bbb1dd-3b49-4c8d-9e2e-8d0a1b5c6744"
      },
      "source": [
        "# Dataset containing sparse tensor\n",
        "dataset4 = tf.data.Dataset.from_tensors(tf.SparseTensor(indices=[[0,0],[1,2]], values=[1,2], dense_shape=[3,4]))\n",
        "\n",
        "dataset4.element_spec.value_type"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.framework.sparse_tensor.SparseTensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8f3-WABPdDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTiSsWzKSjWH",
        "colab_type": "text"
      },
      "source": [
        "### Batching\n",
        "The simplest form of batching stacks `n` consecutive elements into a single element."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI5P5GIaSxRo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d51cc1e9-d32e-4a2d-954a-91ad6c32e782"
      },
      "source": [
        "inc_dataset = tf.data.Dataset.range(100)\n",
        "dec_dataset = tf.data.Dataset.range(0, 100, -1)\n",
        "dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))\n",
        "batched_dataset = dataset.batch(4)\n",
        "\n",
        "# print(inc_dataset, dec_dataset)\n",
        "itr = iter(batched_dataset)\n",
        "for batch in batched_dataset.take(4):\n",
        "  print(batch)\n",
        "  print([a.numpy() for a in batch])\n",
        "\n",
        "print(batched_dataset)\n",
        "\n",
        "batched_dataset = dataset.batch(7, drop_remainder=True)\n",
        "batched_dataset"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: ((None,), (None,)), types: (tf.int64, tf.int64)>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((7,), (7,)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qCjvIYITFeh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "acb0bbf3-87b8-4f60-deb4-77f1c871c7f0"
      },
      "source": [
        "# Padding on different size of the tensors\n",
        "dataset = tf.data.Dataset.range(100)\n",
        "dataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\n",
        "dataset = dataset.padded_batch(4, padded_shapes=(None,))\n",
        "\n",
        "for batch in dataset.take(4):\n",
        "  print(batch.numpy())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0]\n",
            " [1 0 0]\n",
            " [2 2 0]\n",
            " [3 3 3]]\n",
            "[[4 4 4 4 0 0 0]\n",
            " [5 5 5 5 5 0 0]\n",
            " [6 6 6 6 6 6 0]\n",
            " [7 7 7 7 7 7 7]]\n",
            "[[ 8  8  8  8  8  8  8  8  0  0  0]\n",
            " [ 9  9  9  9  9  9  9  9  9  0  0]\n",
            " [10 10 10 10 10 10 10 10 10 10  0]\n",
            " [11 11 11 11 11 11 11 11 11 11 11]]\n",
            "[[12 12 12 12 12 12 12 12 12 12 12 12  0  0  0]\n",
            " [13 13 13 13 13 13 13 13 13 13 13 13 13  0  0]\n",
            " [14 14 14 14 14 14 14 14 14 14 14 14 14 14  0]\n",
            " [15 15 15 15 15 15 15 15 15 15 15 15 15 15 15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdMmoyrVUy9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}